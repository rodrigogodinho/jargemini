{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Instalar o google-genai\n",
        "%pip -q install google-genai"
      ],
      "metadata": {
        "id": "SBN3JFXdCHu-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar as dependências\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import files # para poder selecionar arquivos de sua máquina e enviar para o colab\n",
        "from IPython.display import display, HTML, Markdown, Image # Para exibir texto formatado no Colab\n",
        "import textwrap # Para formatar melhor a saída de texto"
      ],
      "metadata": {
        "id": "FHbN7VxfCW3-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar variável de ambiente com sua GOOGLE_API_KEY\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "Uy0RvSH0CaAH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função auxiliar para exibir texto formatado em Markdown no Colab\n",
        "def to_markdown(text):\n",
        "    text = text.replace('•', '  *')\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "7frkP5snCugq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# função responsável pelo chat\n",
        "def chat():\n",
        "\n",
        "    client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "    model = \"gemini-2.0-flash\"\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "    response_mime_type=\"text/plain\",\n",
        "    system_instruction = \"\"\"\n",
        "      Você é um assistente de jardinagem chamado JarGemini, mas também é especialistas em plantas frutiferas e ornamentais.\n",
        "      Você sempre apresenta respostas que podem ajudar a resolver os problemas das plantas das pessoas,\n",
        "      mas evitar dar respostas muito longas, somente dá respostas longas quando realmente é necessário.\n",
        "\n",
        "      Você informa dados técnicos, como nomes de espécies, mas sempre usa uma linguagem simples, para\n",
        "      que todas as pessoas possam entender, mesmo que não sejam especialistas como você.\n",
        "      Quase sempre, quando é relevante, você adiciona links de vídeos, fotos, ou outros tipos de link,\n",
        "      ao final da resposta, para torná-la mais completa.\n",
        "\n",
        "      Caso não seja enviada uma imagem para análise ou a pergunta é não tem detalhes suficientes, ou não\n",
        "      façam sentido em relação ao histórico da conversa, você pedirá mais detalhes, ou que envie uma foto,\n",
        "      para que você possa entender melhor o caso e tentar ajudar da melhor forma possível.\n",
        "\n",
        "      Você adora ajudar as pessoas com suas plantas e sempre que possível aproveita para demonstrar que\n",
        "      é um grande palmeirense.\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    # Lista para armazenar o histórico de mensagens do chat\n",
        "    chat_history = []\n",
        "\n",
        "    while True:\n",
        "        print(\"Faça sua pergunta sobre plantas: \")\n",
        "        user_input = input()\n",
        "\n",
        "        if user_input.lower() == \"sair\":\n",
        "            break\n",
        "\n",
        "        filename = None\n",
        "        contents = []\n",
        "        uploaded_file_path = None # Variável para armazenar o caminho do arquivo local\n",
        "\n",
        "        # Verifica se o usuário deseja enviar um arquivo\n",
        "        print(\"-------------------------------------------------------------\")\n",
        "        print(\"Gostaria de enviar foto referente o assunto ? (Caso não deseje enviar uma foto é só cancelar): \")\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "          filename = list(uploaded.keys())[0]\n",
        "          uploaded_file_path = filename # Armazena o caminho local do arquivo\n",
        "          print(\"-------------------------------------------------------------\")\n",
        "          print(\"Visualização da imagem enviada:\")\n",
        "          display(Image(filename=uploaded_file_path)) # Exibe a imagem diretamente no Colab\n",
        "\n",
        "        contents.append(\n",
        "            types.Content(\n",
        "                role=\"user\",\n",
        "                parts=[types.Part.from_text(text=user_input)],\n",
        "            )\n",
        "        )\n",
        "        # Verifica se o input do usuário parece ser um caminho de arquivo de imagem\n",
        "        if filename and os.path.exists(filename) and filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "            try:\n",
        "                # Faz o upload do arquivo\n",
        "                uploaded_file = client.files.upload(file=filename)\n",
        "                if uploaded_file:\n",
        "                    # Adiciona a imagem à lista de conteúdos\n",
        "                    contents.append(\n",
        "                        types.Content(\n",
        "                            role=\"user\",\n",
        "                            parts=[\n",
        "                                types.Part.from_uri(\n",
        "                                    file_uri=uploaded_file.uri,\n",
        "                                    mime_type=uploaded_file.mime_type,\n",
        "                                )\n",
        "                            ],\n",
        "                        )\n",
        "                    )\n",
        "                    # uma vez que já foi feito o upload para o Gemini excluimos arquivo do Colab\n",
        "                    os.system(f\"rm -f {filename}\")\n",
        "                else:\n",
        "                    print(\"Erro ao fazer upload do arquivo\")\n",
        "                    continue\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao processar a imagem: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Adiciona a mensagem do usuário ao histórico\n",
        "        chat_history.extend(contents)\n",
        "\n",
        "        # Envia o histórico completo para manter o contexto (opcional, dependendo do modelo)\n",
        "        try:\n",
        "            response_chunks = client.models.generate_content_stream(\n",
        "                model=model,\n",
        "                contents=chat_history,\n",
        "                config=generate_content_config,\n",
        "            )\n",
        "            print(\"Gemini:\", end=\" \")\n",
        "            full_response = \"\"\n",
        "            for chunk in response_chunks:\n",
        "                # print(chunk.text, end=\"\")\n",
        "                full_response += chunk.text\n",
        "            print(\"\\n\")\n",
        "            # Adiciona a resposta do modelo ao histórico\n",
        "            chat_history.append(types.Content(role=\"model\", parts=[types.Part.from_text(text=full_response)]))\n",
        "            print(\"-------------------------------------------------------------\")\n",
        "            print(\"Resposta do JarGemini( Seu assistente de Jardinagem ):\")\n",
        "            print(\"-------------------------------------------------------------\")\n",
        "            display(to_markdown(full_response))\n",
        "            print(\"-------------------------------------------------------------\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ocorreu um erro na comunicação com o modelo: {e}\")"
      ],
      "metadata": {
        "id": "gDUNxtKVCzuJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Executando a função do chat assistente de jardimagem\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Bem-vindo ao JarGemini, seu assistente de jardinagem! Digite 'sair' para encerrar.\")\n",
        "    chat()"
      ],
      "metadata": {
        "id": "Y6eEIOrOELk1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}